# 引言

机器学习（machine learning，ML）是一类强大的可以从经验中学习的技术。

### 训练过程通常包含如下步骤：

1. 从一个随机初始化参数的模型开始，这个模型基本没有“智能”；

2. 获取一些数据样本（例如，音频片段以及对应的是或否标签）；

3. 调整参数，使模型在这些样本中表现得更好；

4. 重复第（2）步和第（3）步，直到模型在任务中的表现令人满意

### 关键组件

1. 可以用来学习的数据（data）；
2. 如何转换数据的模型（model）；
3. 一个目标函数（objective function），用来量化模型的有效性；
4. 调整模型参数以优化目标函数的算法（algorithm）。

#### 数据

每个数据集由一个个**样本**（example, sample）组成，大多时候，它们遵循**独立同分布**(independently and identically distributed, i.i.d.)。

样本有时也叫做**数据点**（data point）或者**数据实例**（data instance），通常每个样本由一组称为**特征**（features，或**协变量**（covariates））的属性组成。 

机器学习模型会根据这些属性进行预测。 在上面的监督学习问题中，要预测的是一个特殊的属性，它被称为**标签**（label，或**目标**（target））。

当每个样本的特征类别数量都是相同的时候，其特征向量是固定长度的，这个长度被称为数据的**维数**（dimensionality）。

#### 模型

深度学习与经典方法的区别主要在于：前者关注的功能强大的模型，这些模型由神经网络错综复杂的交织在一起，包含层层数据转换，因此被称为深度学习（deep learning）。

####  目标函数

在机器学习中，我们需要定义模型的优劣程度的度量，这个度量在大多数情况是“可优化”的，这被称之为**目标函数**（objective function）。

我们通常定义一个目标函数，并希望优化它到最低点。 因为越低越好，所以这些函数有时被称为**损失函数**（loss function，或cost function）

当任务在试图预测数值时，最常见的损失函数是**平方误差**（squared error），即预测值与实际值之差的平方


当一个模型在训练集上表现良好，但不能推广到测试集时，这个模型被称为**过拟合**（overfitting）的。 就像在现实生活中，尽管模拟考试考得很好，真正的考试不一定百发百中。


#### 优化算法

当我们获得了一些**数据源**及其表示、一个**模型**和一个合适的**损失函数**，接下来就需要一种**算法**，它能够搜索出最佳参数，以最小化损失函数。 

深度学习中，大多流行的优化算法通常基于一种基本方法–**梯度下降**（gradient descent）


### 机器学习问题

####  监督学习 

监督学习（supervised learning）擅长在**给定输入特征**的情况下预测标签。 

每个“特征-标签”对都称为一个样本（example）。

##### 回归

