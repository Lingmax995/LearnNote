
---

# 🗓 两年路线总览（24 个月）

## **阶段 1：入门与搭建基础（Month 1–6）**

**目标**：熟悉非结构化环境仿真与规划/决策基础，快速搭建实验环境。

| 月份      | 工作内容                              | 实验 / Baseline             | 产出                 |
| ------- | --------------------------------- | ------------------------- | ------------------ |
| Month 1 | 安装 ROS + Gazebo / CARLA，熟悉环境      | 跑仿真车辆基础移动                 | -                  |
| Month 2 | 学习经典路径规划算法（A*, Hybrid A*, RRT*）   | 在非结构化地图（简单障碍物/地形）上实现路径规划  | -                  |
| Month 3 | 收集数据 & 构建可通行性地图（RUGD / RELLIS-3D） | 使用已有数据生成可通行性标注            | -                  |
| Month 4 | 将路径规划算法结合可通行性地图                   | 路径规划实验：A* / RRT* + 可通行性约束 | -                  |
| Month 5 | 学习行为决策基础（FSM / 基础规则）              | FSM 决策 + 路径规划结合，测试避障和越野行驶 | -                  |
| Month 6 | 初步整合感知 → 可通行性 → 规划 → 决策           | 小型仿真实验验证整体 pipeline       | 小型实验报告，可作为后续论文数据基础 |

---

## **阶段 2：快速出论文 / 基础改进（Month 7–12）**

**目标**：在入门基础上做小改进，尝试第一篇论文。

| 月份       | 工作内容                             | 实验 / Baseline                      | 产出      |
| -------- | -------------------------------- | ---------------------------------- | ------- |
| Month 7  | 改进路径规划效率（启发式优化 / 多线程 / 学习辅助启发函数） | 与原始 A* / RRT* 做对比                  | -       |
| Month 8  | 优化行为决策规则（结合可通行性地图的避障优先策略）        | FSM baseline vs 改进策略               | -       |
| Month 9  | 小规模实验：不同地形 / 天气条件                | CARLA 或 Gazebo 仿真 5–10 种非结构化地形     | 数据分析、图表 |
| Month 10 | 整理实验结果                           | 对比 baseline 路径规划 + 行为决策            | -       |
| Month 11 | 撰写第一篇论文（EI 或 SCI 四区）             | 主题：**非结构化环境下路径规划 + 可通行性地图结合的行为决策** | 投稿      |
| Month 12 | 完成论文修改 / 投稿                      | -                                  | 第一篇论文完成 |

---

## **阶段 3：强化学习 / 模仿学习改进（Month 13–18）**

**目标**：将 RL / 模仿学习加入决策层，提升智能性与泛化能力。

| 月份       | 工作内容                                       | 实验 / Baseline                | 产出 |
| -------- | ------------------------------------------ | ---------------------------- | -- |
| Month 13 | 学习 RL / Imitation Learning（PPO / DQN / BC） | 在 CARLA 环境跑基础 RL 模型          | -  |
| Month 14 | 实现行为决策 RL baseline                         | RL 决策 + 原 FSM 决策对比           | -  |
| Month 15 | 将 RL 决策结合可通行性地图                            | 实验：感知输出驱动 RL 决策              | -  |
| Month 16 | 不同地形/障碍/环境泛化实验                             | 比较 RL 决策 vs FSM / 规则决策       | -  |
| Month 17 | 调整 reward / 网络结构，提高稳定性                     | 实验优化 RL 收敛效果                 | -  |
| Month 18 | 撰写第二篇论文（SCI 三区）                            | 主题：**非结构化环境下的 RL /模仿学习行为决策** | 投稿 |

---

## **阶段 4：综合实验与高水平提升（Month 19–24）**

**目标**：形成完整 pipeline，可在复杂环境中稳定运行，准备冲 SCI 二区论文。

| 月份       | 工作内容                        | 实验 / Baseline                             | 产出             |
| -------- | --------------------------- | ----------------------------------------- | -------------- |
| Month 19 | 整合感知（可通行性地图）、路径规划、RL决策      | 整体 pipeline 仿真实验                          | -              |
| Month 20 | 多场景泛化实验（不同地形/天气/障碍分布）       | 与前期 baseline 比对                           | -              |
| Month 21 | 引入实验评估指标（效率、安全性、平滑性、成功率）    | 分析各模型性能                                   | -              |
| Month 22 | 调整参数 / 网络 / reward，提高稳定性和泛化 | 最终模型调试                                    | -              |
| Month 23 | 撰写第三篇论文（SCI二区）              | 主题：**非结构化环境下综合感知 + 可通行性 + 路径规划 + RL行为决策** | 投稿             |
| Month 24 | 总结与整理成果                     | 整理数据、代码、报告                                | 成熟科研成果，技能可转化工作 |

---

## 📌 备注与建议

1. **数据集**：RUGD、RELLIS-3D，实验环境 CARLA / Gazebo，尽量复现已有 baseline 方便发表论文。
2. **硬件要求**：中等 GPU 就能跑 RL / CNN 感知；不必依赖大型多模态传感器。
3. **技能收益**：

   * 路径规划、行为决策、RL/模仿学习
   * ROS/Gazebo/CARLA 仿真
   * 数据分析、论文写作、科研方法
   * 技能直接可用在无人车、AGV、越野/农业/矿山车辆等实际工程项目。
4. **论文级别**：

   * 阶段 2 → EI / SCI 四区
   * 阶段 3 → SCI 三区
   * 阶段 4 → SCI 二区（可冲高水平）

---
